AWSTemplateFormatVersion: 2010-09-09
Description: >-
  This template creates Databricks workspace resources in your AWS account using the API account. The API account is required if you want to use either customer managed VPCs or customer managed keys for notebooks. For feature availability, contact your Databricks representative. (qs-1r0odiedc)
Metadata:
  QuickStartDocumentation:
    EntrypointName: "Parameters for deploying a workspace and creating a cross-account IAM role"
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: "Workspace configuration"
        Parameters:
          - AccountId
          - Username
          - Password
          - PricingTier
          - DeploymentName
          - AWSRegion
          - HIPAAparm
      - Label:
          default: "IAM role and S3 bucket configuration"
        Parameters:
          - TagValue
          - ExistingCrossAccountIAMRoleARN
          - ExistingCrossAccountIAMRoleName
          - NewCrossAccountIAMRoleName
          - BucketName
      - Label:
          default: "(Optional) Customer managed key configuration for notebooks (requires the enterprise tier)"
        Parameters:
          - NewKMSKeyAlias
          - KeyUseCases
          - KeyReuseForClusterVolumes
      - Label:
          default: "Quick Start configuration"
        Parameters:
          - QSS3BucketName
          - QSS3KeyPrefix
    ParameterLabels:
      AccountId:
        default: Databricks account ID
      Username:
        default: Workspace account email
      Password:
        default: Workspace account password
      PricingTier:
        default: Pricing tier of the workspace
      DeploymentName:
        default: Workspace deployment name
      AWSRegion:
        default: AWS Region of the Databricks workspace
      HIPAAparm:
        default: HIPAA tier account
      TagValue:
        default: IAM role tag
      IAMRoleARN:
        default: Cross-account IAM role ARN
      BucketName:
        default: Root S3 bucket name
      NewKMSKeyAlias:
        default: Alias for the customer managed AWS KMS key
      KeyUseCases:
        default: Use case for which to use the key
      KeyReuseForClusterVolumes:
        default: Encrypt cluster EBS volumes
      QSS3BucketName:
        default: Quick Start S3 bucket name
      QSS3KeyPrefix:
        default: Quick Start S3 key prefix

Outputs:
  CustomerManagedVPCIAMRoleARN:
    Description: ARN of the customer managed cross-account IAM role.
    Condition: CreateCrossAccountIAMRole
    Value: !Ref accessRoleCustomerManagedVPC
  S3BucketName:
    Description: Name of the S3 root bucket.
    Value: !Ref assetsS3Bucket
#  CustomerManagedKeyId:
#    Description: ID of the customer managed key object.
#    Condition: CMKEncrypted
#    Value: !GetAtt createCustomerManagedKey.CustomerManagedKeyId
#  CredentialsId:
#    Description: Credential ID.
#    Value: !GetAtt createCredentials.CredentialsId
#  ExternalId:
#    Description: Databricks external ID.
#    Value: !GetAtt createCredentials.ExternalId
#  NetworkId:
#    Description: Databricks network ID.
#    Value: !GetAtt createNetworks.NetworkId
#  StorageConfigId:
#    Description: Storage configuration ID.
#    Value: !GetAtt createStorageConfiguration.StorageConfigId
#  WorkspaceURL:
#    Description: URL of the workspace.
#    Value: !Join
#      - ''
#      - - 'https://'
#        - !GetAtt createWorkspace.DeploymentName
#        - '.cloud.databricks.com'
#  WorkspaceStatus:
#    Description: Status of the requested workspace.
#    Value: !GetAtt createWorkspace.WorkspaceStatus
#  WorkspaceStatusMessage:
#    Description: Detailed status description of the requested workspace.
#    Value: !GetAtt createWorkspace.WorkspaceStatusMsg
#  PricingTier:
#    Description: Pricing tier of the workspace. For more information, see https://databricks.com/product/aws-pricing.
#    Value: !GetAtt createWorkspace.PricingTier
#  ClusterPolicyID:
#    Description: Unique identifier for the cluster policy.
#    Value: !GetAtt createWorkspace.ClusterPolicyId

Parameters:
  AccountId:
    Description: "Account must use the E2 version of the platform. For more information, see https://docs.databricks.com/getting-started/overview.html#e2-architecture."
    AllowedPattern: '^[a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12}$'
    MinLength: '36'
    Type: String
    Default: '3e1e9412-2afe-477a-9471-4d16cba26cf3'
  Username:
    Description: "Account email for authenticating the REST API. Note that this value is case sensitive."
    AllowedPattern: '^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+.[a-zA-Z0-9-.]+$'
    ConstraintDescription: Must be a valid email format.
    MinLength: '8'
    Type: String
    Default: 'ganesh.krishnamurthy@bakerhughes.com'
  Password:
    Description: "Account password for authenticating the REST API. The minimum length is 8 alphanumeric characters."
    MinLength: '8'
    NoEcho: 'true'
    Type: String
  PricingTier:
    Description: "If you do not provide this, the API defaults to the highest pricing tier. For more information, see https://databricks.com/product/aws-pricing."
    AllowedValues:
       - STANDARD
       - PREMIUM
       - ENTERPRISE
       - ''
    Type: String
    Default: 'ENTERPRISE'
  DeploymentName:
    Description: "Choose this value carefully. The deployment name defines part of the workspace subdomain (e.g., workspace-deployment-name.cloud.databricks.com). This value must be unique across all deployments in all AWS Regions. It cannot start or end with a hyphen. If your account has a deployment-name prefix, add the prefix followed by a hyphen. For more information, see https://docs.databricks.com/administration-guide/account-api/new-workspace.html#step-5-create-the-workspace."
    AllowedPattern: '^(([a-z0-9][a-z0-9-]*[a-z0-9])|([a-z0-9]))$'
    ConstraintDescription: You must enter a valid subdomain for the workspace.
    Type: String
    Default: 'bhdatabrickspoc'
  AWSRegion:
    Description: "AWS Region where the workspace is created. Note that customer managed keys to encrypt notebooks are not supported in the us-west-1 Region."
    MinLength: '9'
    AllowedValues:
       - ap-northeast-1
       - ap-south-1
       - ap-southeast-2
       - ca-central-1
       - eu-central-1
       - eu-west-1
       - eu-west-2
       - us-east-1
       - us-east-2
       - us-west-1
       - us-west-2
    Type: String
    Default: 'us-east-1'
  HIPAAparm:
    Description: 'Entering "Yes" creates a template for creating clusters in the HIPAA account.'
    AllowedValues:
       - 'Yes'
       - 'No'
    Default: 'No'
    Type: String
  TagValue:
    Description: "All new AWS objects get a tag with the key name. Enter a value to identify all new AWS objects that this template creates. For more information, see https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html."
    MinLength: '1'
    Type: String
    Default: databricks-quickstart-cloud-formation
  ExistingCrossAccountIAMRoleARN:
    Description: "Enter the ARN of an existing cross-account IAM role, ensuring it meets the requirements here: https://docs.databricks.com/administration-guide/account-api/iam-role.html"
    Type: String
    Default: 'arn:aws:iam::040138105032:role/BHDatabricks'
  ExistingCrossAccountIAMRoleName:
    Description: "Enter the role name of the existing cross-account IAM role"
    Type: String
    Default: 'BHDatabricks'
  NewCrossAccountIAMRoleName:
    Description: "Enter a unique cross-account IAM role name. For more information, see https://docs.aws.amazon.com/IAM/latest/APIReference/API_CreateRole.html."
    Type: String
    Default: ''
  DatabricksS3SecureAccessRoleName:
    Description: "Enter a IAM role name. For more information, see https://docs.aws.amazon.com/IAM/latest/APIReference/API_CreateRole.html."
    Type: String
    Default: 'databricks-s3-secure-access-role'
  DatabricksIAMInstanceProfileName:
    Description: "Enter a name for the instance profile. This parameter allows a string of characters consisting of upper and lowercase alphanumeric characters with no spaces. You can also include any of the following characters: _+=,.@-"
    Type: String
    Default: 'databricks-IAM-instance-profile'
  BucketName:
    Description: "Name of your S3 root bucket. Enter only alphanumeric characters. For more information, see https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html."
    AllowedPattern: '(?=^.{3,63}$)(?!xn--)([a-z0-9](?:[a-z0-9-]*)[a-z0-9])$'
    MinLength: '3'
    MaxLength: '63'
    Type: String
    Default: 'bhdatabrickspoc'
    ConstraintDescription: Quick Start bucket name can include numbers, lowercase letters, uppercase letters, and hyphens (-). It cannot start or end with a hyphen (-).
  ApplicationDataS3BucketName:
    Description: "Name of your Application Data S3 bucket. Enter only alphanumeric characters. For more information, see https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html."
    AllowedPattern: '(?=^.{3,63}$)(?!xn--)([a-z0-9](?:[a-z0-9-]*)[a-z0-9])$'
    MinLength: '3'
    MaxLength: '63'
    Type: String
    Default: 'bhdatabricks-application-data'
    ConstraintDescription: Quick Start bucket name can include numbers, lowercase letters, uppercase letters, and hyphens (-). It cannot start or end with a hyphen (-).
  HVRStagingS3BucketName:
    Description: "Name of your HVR Staging S3 bucket. Enter only alphanumeric characters. For more information, see https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html."
    AllowedPattern: '(?=^.{3,63}$)(?!xn--)([a-z0-9](?:[a-z0-9-]*)[a-z0-9])$'
    MinLength: '3'
    MaxLength: '63'
    Type: String
    Default: 'bhdatabricks-hvr-staging-data'
    ConstraintDescription: Quick Start bucket name can include numbers, lowercase letters, uppercase letters, and hyphens (-). It cannot start or end with a hyphen (-).
  DataMigration3BucketName:
    Description: "Name of your HVR Staging S3 bucket. Enter only alphanumeric characters. For more information, see https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html."
    AllowedPattern: '(?=^.{3,63}$)(?!xn--)([a-z0-9](?:[a-z0-9-]*)[a-z0-9])$'
    MinLength: '3'
    MaxLength: '63'
    Type: String
    Default: '040138105032-us-east-1-datamigration-repl'
    ConstraintDescription: Quick Start bucket name can include numbers, lowercase letters, uppercase letters, and hyphens (-). It cannot start or end with a hyphen (-).
  Sftp3BucketName:
    Description: "Name of your HVR Staging S3 bucket. Enter only alphanumeric characters. For more information, see https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html."
    AllowedPattern: '(?=^.{3,63}$)(?!xn--)([a-z0-9](?:[a-z0-9-]*)[a-z0-9])$'
    MinLength: '3'
    MaxLength: '63'
    Type: String
    Default: '040138105032-us-east-1-bhcaspiasftpcommon02001d'
    ConstraintDescription: Quick Start bucket name can include numbers, lowercase letters, uppercase letters, and hyphens (-). It cannot start or end with a hyphen (-).
  VPCID:
    Description: "ID of your VPC in which to create the new workspace. Only enter a value if you use the customer managed VPC feature. The format is vpc-xxxxxxxxxxxxxxxx. If unspecified, Databricks creates a new workspace in a new VPC. For more information, see https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html."
    Type: String
    Default: 'vpc-0f1286174903e9e24'
  SecurityGroupIDs:
    Description: "Name of one or more VPC security groups. Only enter a value if you set VPCID. The format is sg-xxxxxxxxxxxxxxxxx. Use commas to separate multiple IDs. Databricks must have access to at least one security group but no more than five. You can reuse existing security groups. For more information, see https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html."
    Type: String
    Default: 'sg-0550d96649a60455c'
  SubnetIDs:
    Description: "Enter at least two private subnet IDs [i.e. subnet-xxxx,subnet-yyyy]. Only enter a value if you set VPCID. Subnets cannot be shared with other workspaces or non-Databricks resources. Each subnet must be private, have outbound access, and a netmask between /17 and /25. The NAT gateway must have its own subnet that routes 0.0.0.0/0 traffic to an internet gateway. For more information, see https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html."
    Type: String
    Default: 'subnet-0485693c2c8bb5bb6,subnet-0d087ed6be9869b10,subnet-044bbe3936e308818,subnet-014aca71fa33540d6'
  NewKMSKeyAlias:
    Description: "(Optional) Creates a new AWS KMS key with the given alias for encrypting data"
    Type: String
    Default: 'bhdatabrickspoc'
  KeyUseCases:
    Description: "Configures customer managed encryption keys. Acceptable values are MANAGED_SERVICES, STORAGE, or BOTH. For more information, see https://docs.databricks.com/administration-guide/account-api/new-workspace.html#step-5-configure-customer-managed-keys-optional."
    Type: String
    Default: 'BOTH'
  KeyReuseForClusterVolumes:
    Description: 'Only enter a value if the use case is STORAGE or BOTH. Acceptable values are "True" and "False."'
    Type: String
    Default: 'True'
  QSS3BucketName:
    Description: "S3 bucket for Quick Start assets. Use this if you want to customize the Quick Start. The bucket name can include numbers, lowercase letters, uppercase letters, and hyphens, but it cannot start or end with a hyphen (-)."
    AllowedPattern: '^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$'
    Default: aws-quickstart
    Type: String
    MinLength: '3'
    MaxLength: '63'
    ConstraintDescription: Quick Start bucket name can include numbers, lowercase letters, uppercase letters, and hyphens (-). It cannot start or end with a hyphen (-).
  QSS3KeyPrefix:
    Description: "S3 key prefix to simulate a directory for your deployment assets.  The prefix can include numbers, lowercase letters, uppercase letters, hyphens (-), and forward slashes (/). For more information, see https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html."
    AllowedPattern: '^[0-9a-zA-Z-/]*$'
    Type: String
    Default: quickstart-databricks-unified-data-analytics-platform/
  FirstTransitionStorageClass:
    Description: Select storage class to which you want the object to transition. It's recommended to transition objects to STANDARD_IA storage class after 30 days.
    Type: String
    AllowedValues: [ DEEP_ARCHIVE , GLACIER , INTELLIGENT_TIERING , ONEZONE_IA , STANDARD_IA ]
    Default: STANDARD_IA
  FirstTransitionInDays:
    Description: Indicates the number of days after creation when objects are transitioned to the specified storage class. The value must be a positive integer. It's recommended to keep it 30 days.
    Type: Number
    Default: 30
  SecondTransitionStorageClass:
    Description: Select storage class to which you want the object to transition. It's recommended to transition objects to GLACIER storage class after 90 days as a second transition.
    Type: String
    AllowedValues: [ DEEP_ARCHIVE , GLACIER , INTELLIGENT_TIERING , ONEZONE_IA , STANDARD_IA ]
    Default: GLACIER
  SecondTransitionInDays:
    Description: Indicates the number of days after creation when objects are transitioned to the specified storage class. The value must be a positive integer. It's recommended to keep it 90 days as a second transition.
    Type: Number
    Default: 90
  ThirdTransitionInDays:
    Description: Indicates the number of days after creation when objects are transitioned to the specified storage class. The value must be a positive integer. It's recommended to keep it 365 days as a third transition.
    Type: Number
    Default: 365
  ThirdTransitionStorageClass:
    Description: Select storage class to which you want the object to transition. It's recommaneded to transtion objects to GLACIER Deep Achieve storage class after 365 days as a third transtion.
    Type: String
    AllowedValues: [ DEEP_ARCHIVE , GLACIER , INTELLIGENT_TIERING , ONEZONE_IA , STANDARD_IA ]
    Default: DEEP_ARCHIVE
  ExpirationInDays:
    Description: Specify the lifecycle of the objects in an Amazon S3 bucket in days, after the expiration period the objects will be deleted from the bucket. It's recommended to keep it 365*5 days.
    Type: Number
    Default: 1825
  DataClassification:
    Description: Select the calss of data stored in the s3 bucket. Note that some actions will be applied to the bucket according to your selection. Temporary bucket means it's created for test purpose without bucket policy. (Mandatory)
    Type: String
    Default: 'confidential/highly-confidential'
    AllowedValues: [ "confidential/highly-confidential" , "Non-confidential"]
  app:
    Description: Enter the Application Name (Mandatory)
    Type: String
    Default: 'bhcaspia'
  uai:
    Description: Enter ServiceNow ID (Mandatory)
    Type: String
    Default: 'UAI9999999999'
  env:
    Description: select the enviroment of the resource (Mandatory)
    Type: String
    Default: 'dev'
    AllowedValues:
      - prod
      - stg
      - qa
      - dev
  role:
    Description: Enter the role of the component. i.e 'admin-resource' (Required)
    Type: String
    Default: app
    AllowedValues:
      - web
      - app
      - database
      - auth
      - emr
      - other


Conditions:
# Set condition when VPC ID is provided by the user
  HasExistingVPC: !Not [!Equals [!Ref VPCID, '']]
# Set condition when VPC ID is NOT provided by the user
  CreateVPC: !Equals [!Ref VPCID, '']
# Set condition when cross-account role should be created by this template
  CreateCrossAccountIAMRole: !Not [!Equals [!Ref NewCrossAccountIAMRoleName, '']]
# Set condition when AWS KMS key ID is provided by the user.
  CMKEncrypted: !Not [!Equals [!Ref NewKMSKeyAlias, '']]
# Test for STORAGE CMK use case
  IsClusterVolumeSet: !Equals [!Ref KeyReuseForClusterVolumes, 'True']

#Rules:
## 1. Validate the selected Region from drop-down matches the Region from the Console
#  RunningTemplateFromDifferentRegionThanDropDown:
#    Assertions:
#    - Assert: !Equals [!Ref AWSRegion, !Ref 'AWS::Region']
#      AssertDescription: Region from the AWS Management Console must match the selected Region from the drop-down menu.
## 2. Ensure that an IAM role name is given when no ARN is provided for an existing cross account IAM role.
#  ExistingCrossAccountIAMRole:
#    RuleCondition: !Not [!Equals [!Ref ExistingCrossAccountIAMRoleARN, '']]
#    Assertions:
#    - Assert: !Equals [!Ref NewCrossAccountIAMRoleName, '']
#      AssertDescription: Name for cross-account IAM role must be given if an existing cross-account IAM Role ARN is not provided.
#    - Assert: !Not [!Equals [!Ref ExistingCrossAccountIAMRoleName, '']]
#      AssertDescription: IAM Role name for existing cross-account role must be specified.
## 3. Ensure that an existing cross-account IAM role ARN is not supplied when an IAM role name is given to create the cross-account role.
#  CreateCrossAccountIAMRole:
#    RuleCondition: !Not [!Equals [!Ref NewCrossAccountIAMRoleName, '']]
#    Assertions:
#    - Assert: !Equals [!Ref ExistingCrossAccountIAMRoleARN, '']
#      AssertDescription: Existing IAM Role ARN should not be given when a new cross-account role name is provided.
## 4. Ensure that the security group ID is supplied when an existing VPC ID is provided.
#  SecurityGroupIDExists:
#    RuleCondition: !Not [!Equals [!Ref VPCID, '']]
#    Assertions:
#    - Assert: !Not [!Equals [!Ref SecurityGroupIDs, '']]
#      AssertDescription: Security Group ID should be supplied when VPC ID is provided.
## 5. Ensure that subnet IDs are supplied when an existing VPC ID is provided.
#  SubnetIDsExist:
#    RuleCondition: !Not [!Equals [!Ref VPCID, '']]
#    Assertions:
#    - Assert: !Not [!Equals [!Ref SubnetIDs, '']]
#      AssertDescription: Subnet IDs should be supplied when VPC ID is provided.
## 4. Optional Section. Ensure the KeyAlias is provided when a use case is specified.
#  KeyUseCases1:
#    RuleCondition: !Not [!Equals [!Ref NewKMSKeyAlias, '']]
#    Assertions:
#    - Assert: !Contains [['MANAGED_SERVICES', 'STORAGE', 'BOTH'],!Ref KeyUseCases]
#      AssertDescription: Acceptable values are MANAGED_SERVICES, STORAGE, or BOTH when you provide a new key alias to be created.
#
#  KeyUseCases2:
#    RuleCondition: !Or
#      - !Equals [!Ref KeyUseCases, 'STORAGE']
#      - !Equals [!Ref KeyUseCases, 'BOTH']
#    Assertions:
#    - Assert: !Contains [['True', 'False'], !Ref KeyReuseForClusterVolumes]
#      AssertDescription: 'Acceptable values are "True" and "False" when the use case is either STORAGE or BOTH.'
#
#  KeyUseCases3:
#    RuleCondition: !Equals [!Ref KeyUseCases, 'MANAGED_SERVICES']
#    Assertions:
#    - Assert: !Equals [!Ref KeyReuseForClusterVolumes, '']
#      AssertDescription: Value must be null if MANAGED_SERVICES is specified.

Resources:
#
#  THE FOLLOWING RESOURCES ONLY APPLY IF THIS TEMPLATE IS CONFIGURING THE VPC
#
# Creates the VPC
  customerManagedVPC:
    Type: 'AWS::EC2::VPC'
    Condition: CreateVPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsHostnames: 'true'
      EnableDnsSupport: 'true'

# Creates private subnet for deployment of EC2 compute, note that CidrBlock and AZ can be changed.
  privateSubnet1:
    Type: AWS::EC2::Subnet
    Condition: CreateVPC
    Properties:
      VpcId: !Ref customerManagedVPC
      AvailabilityZone: "us-east-1a"
      CidrBlock: 10.0.0.0/24

# Creates private subnet for deployment of EC2 compute, note that CidrBlock and AZ can be changed.
  privateSubnet2:
    Type: AWS::EC2::Subnet
    Condition: CreateVPC
    Properties:
      CidrBlock: 10.0.1.0/24
      VpcId: !Ref customerManagedVPC
      AvailabilityZone: "us-east-1b"

# Public subnet is required for outbound internet access for installation of external libraries (i.e. Maven, PyPI, CRAN)
  publicSubnet:
    Type: AWS::EC2::Subnet
    Condition: CreateVPC
    Properties:
      CidrBlock: 10.0.2.0/24
      VpcId: !Ref customerManagedVPC
      AvailabilityZone: "us-east-1c"
      MapPublicIpOnLaunch: 'true'

# Internet Gateway that is required to route outbound requests
  internetGateway:
    Type: AWS::EC2::InternetGateway
    Condition: CreateVPC

# Attaches Internet Gateway to VPC
  internetGatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Condition: CreateVPC
    Properties:
      InternetGatewayId: !Ref internetGateway
      VpcId: !Ref customerManagedVPC

# Elastic IP address for the NAT Gateway
  NatGateway1EIP:
    Type: AWS::EC2::EIP
    Condition: CreateVPC
    DependsOn: internetGatewayAttachment
    Properties:
      Domain: vpc

# Specifies a network address translation (NAT) gateway in the specified subnet.
  NatGateway1:
    Type: AWS::EC2::NatGateway
    Condition: CreateVPC
    Properties:
      AllocationId: !GetAtt NatGateway1EIP.AllocationId
      SubnetId: !Ref publicSubnet

# RouteTable for public access
  PublicRouteTable:
    Type: AWS::EC2::RouteTable
    Condition: CreateVPC
    Properties:
      VpcId: !Ref customerManagedVPC

# Routtes all outbound public traffic to the internet gateway
  DefaultPublicRoute:
    Type: AWS::EC2::Route
    Condition: CreateVPC
    DependsOn: internetGatewayAttachment
    Properties:
      RouteTableId: !Ref PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref internetGateway

# Associates Route table with public subnet for outbound public traffic
  PublicSubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Condition: CreateVPC
    Properties:
      RouteTableId: !Ref PublicRouteTable
      SubnetId: !Ref publicSubnet

# Private Route Table for private subnets
  PrivateRouteTable1:
    Type: AWS::EC2::RouteTable
    Condition: CreateVPC
    Properties:
      VpcId: !Ref customerManagedVPC

# Private Route, routes public traffic to the Nat Gateway
  DefaultPrivateRoute1:
    Type: AWS::EC2::Route
    Condition: CreateVPC
    Properties:
      RouteTableId: !Ref PrivateRouteTable1
      DestinationCidrBlock: 0.0.0.0/0
      NatGatewayId: !Ref NatGateway1

# Associate RouteTable with private subnet
  PrivateSubnet1RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Condition: CreateVPC
    Properties:
      RouteTableId: !Ref PrivateRouteTable1
      SubnetId: !Ref privateSubnet1

# Associate RouteTable with private subnet
  PrivateSubnet2RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Condition: CreateVPC
    Properties:
      RouteTableId: !Ref PrivateRouteTable1
      SubnetId: !Ref privateSubnet2

# Security Group
  SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Condition: CreateVPC
    Properties:
      VpcId: !Ref customerManagedVPC
      GroupDescription: Security group for Databricks E2 deployment

# Security Group Ingress, according to the following: https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html#security-groups
  SecurityGroupIngressTcp:
    Type: AWS::EC2::SecurityGroupIngress
    Condition: CreateVPC
    Properties:
      GroupId: !Ref SecurityGroup
      SourceSecurityGroupId: !Ref SecurityGroup
      IpProtocol: tcp
      FromPort: 0
      ToPort: 65535

# Security group Ingress, according to the following: https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html#security-groups
  SecurityGroupIngressUdp:
    Type: AWS::EC2::SecurityGroupIngress
    Condition: CreateVPC
    Properties:
      GroupId: !Ref SecurityGroup
      SourceSecurityGroupId: !Ref SecurityGroup
      IpProtocol: udp
      FromPort: 0
      ToPort: 65535

# Security Group Egress, according to the following: https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html#security-groups
  SecurityGroupEgressAll:
    Type: AWS::EC2::SecurityGroupEgress
    Condition: CreateVPC
    Properties:
      GroupId: !Ref SecurityGroup
      CidrIp: 0.0.0.0/0
      IpProtocol: -1

# Network ACL
  NetworkAcl:
    Type: AWS::EC2::NetworkAcl
    Condition: CreateVPC
    Properties:
      VpcId: !Ref customerManagedVPC

# Network ACL Entry, adhering to the following: https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html#subnet-level-network-acls
  NetworkAclEntryInboundAllow:
    Type: AWS::EC2::NetworkAclEntry
    Condition: CreateVPC
    Properties:
      Egress: "false"
      CidrBlock: 0.0.0.0/0
      Protocol: -1
      RuleNumber: 100
      RuleAction: allow
      NetworkAclId: !Ref NetworkAcl

# Network ACL Entry, adhering to the following: https://docs.databricks.com/administration-guide/cloud-configurations/aws/customer-managed-vpc.html#subnet-level-network-acls
  NetworkAclEntryOutboundAllow:
    Type: AWS::EC2::NetworkAclEntry
    Condition: CreateVPC
    Properties:
      Egress: "true"
      CidrBlock: 0.0.0.0/0
      Protocol: -1
      RuleNumber: 100
      RuleAction: allow
      NetworkAclId: !Ref NetworkAcl

# Associate Subnet Network ACL with subnet
  SubnetNetworkAclNAT:
    Type: AWS::EC2::SubnetNetworkAclAssociation
    Condition: CreateVPC
    Properties:
      NetworkAclId: !Ref NetworkAcl
      SubnetId: !Ref publicSubnet

# Associate SubnetNetwork ACL with subnet
  SubnetNetworkAclPrivateSubnet1:
    Type: AWS::EC2::SubnetNetworkAclAssociation
    Condition: CreateVPC
    Properties:
      NetworkAclId: !Ref NetworkAcl
      SubnetId: !Ref privateSubnet1

  SubnetNetworkAclPrivateSubnet2:
    Type: AWS::EC2::SubnetNetworkAclAssociation
    Condition: CreateVPC
    Properties:
      NetworkAclId: !Ref NetworkAcl
      SubnetId: !Ref privateSubnet2

#
# THE FOLLOWING RESOURCES ARE USED FOR PRIVATELINK
#
  #VPCEndpointS3:
   # Type: AWS::EC2::VPCEndpoint
    #Properties:
     # RouteTableIds:
      #  - !Ref PrivateRouteTable1
      #ServiceName: 'com.amazonaws.us-east-1.s3'
      #VpcId: !Ref customerManagedVPC
  #VPCEndpointSTS:
   # Type: AWS::EC2::VPCEndpoint
    #Properties:
     # VpcEndpointType: Interface
      #PrivateDnsEnabled: true
      #SecurityGroupIds:
       # - !Ref SecurityGroup
      #SubnetIds:
       # - !Ref privateSubnet1
        #- !Ref privateSubnet2
      #ServiceName: 'com.amazonaws.sts'
      #VpcId: !Ref customerManagedVPC
  #VPCEndpointKinesis:
   # Type: AWS::EC2::VPCEndpoint
    #Properties:
     # VpcEndpointType: Interface
      #PrivateDnsEnabled: true
      #SecurityGroupIds:
       # - !Ref SecurityGroup
      #SubnetIds:
       # - !Ref privateSubnet1
        #- !Ref privateSubnet2
      #ServiceName: 'com.amazonaws.us-east-1.kinesis'
      #VpcId: !Ref customerManagedVPC
  #VPCEndpointWorkspace:
   # Type: AWS::EC2::VPCEndpoint
    #Properties:
     # VpcEndpointType: Interface
      #PrivateDnsEnabled: true
      #SecurityGroupIds:
       # - !Ref VPCEndpointSG
      #SubnetIds:
       # - !Ref VPCEndpointSubnet
      #ServiceName: 'com.amazonaws.vpce.us-east-1.vpce-svc-09143d1e626de2f04'
      #VpcId: !Ref customerManagedVPC
  #VPCEndpointSCC:
   # Type: AWS::EC2::VPCEndpoint
    #Properties:
     # VpcEndpointType: Interface
      #PrivateDnsEnabled: true
      #SecurityGroupIds:
       # - !Ref VPCEndpointSG
      #SubnetIds:
       # - !Ref VPCEndpointSubnet
      #ServiceName: 'com.amazonaws.vpce.us-east-1.vpce-svc-00018a8c3ff62ffdf'
      #VpcId: !Ref customerManagedVPC
  #VPCEndpointSubnet:
   # Type: AWS::EC2::Subnet
    #Properties:
     # CidrBlock: 10.0.3.0/24
      #VpcId: !Ref customerManagedVPC
      #AvailabilityZone: "us-east-1d"
  #VPCEndpointSG:
   # Type: AWS::EC2::SecurityGroup
    #Properties:
     # GroupDescription: Allow VPC endpoint services to reach control plane infra
      #VpcId: !Ref customerManagedVPC
  #SecurityGroupEgressRest:
   # Type: AWS::EC2::SecurityGroupEgress
    #Properties:
     # DestinationSecurityGroupId: !Ref VPCEndpointSG
      #GroupId: !Ref VPCEndpointSG
      #IpProtocol: tcp
      #FromPort: 443
      #ToPort: 443
  #SecurityGroupEgressPL:
   # Type: AWS::EC2::SecurityGroupEgress
    #Properties:
     # DestinationSecurityGroupId: !Ref VPCEndpointSG
      #GroupId: !Ref VPCEndpointSG
      #IpProtocol: tcp
      #FromPort: 6666
      #ToPort: 6666
  #SecurityGroupIngressRest:
   # Type: AWS::EC2::SecurityGroupIngress
    #Properties:
     # SourceSecurityGroupId: !Ref VPCEndpointSG
      #GroupId: !Ref VPCEndpointSG
      #IpProtocol: tcp
      #FromPort: 443
      #ToPort: 443
  #SecurityGroupIngressPL:
   # Type: AWS::EC2::SecurityGroupIngress
    #Properties:
     # SourceSecurityGroupId: !Ref VPCEndpointSG
      #GroupId: !Ref VPCEndpointSG
      #IpProtocol: tcp
      #FromPort: 6666
      #ToPort: 6666

#
# THE FOLLOWING RESOURCE ONLY APPLIES IF YOU WANT THIS TEMPLATE TO CREATE THE CROSS-ACCOUNT IAM ROLE.
#

# Create cross-account IAM role, according to the following: https://docs.databricks.com/administration-guide/account-api/iam-role.html

  accessRoleCustomerManagedVPC:
    Type: 'AWS::IAM::Role'
    Metadata:
      cfn-lint:
        config:
          ignore_checks:
            - EIAMPolicyWildcardResource
          ignore_reasons:
            EIAMPolicyWildcardResource: "Must manage databricks workspaces."
    Condition: CreateCrossAccountIAMRole
    Properties:
      RoleName: !Ref NewCrossAccountIAMRoleName
      AssumeRolePolicyDocument:
        Statement:
          - Action: 'sts:AssumeRole'
            Condition:
               StringEquals:
                'sts:ExternalId': !Sub '${AccountId}'
            Effect: Allow
            Principal:
              AWS: !Join
                - ''
                - - 'arn:aws:iam::'
                  - '414351767826'
                  - ':root'
            Sid: ''
        Version: 2012-10-17
      Path: /
      Policies:
        - PolicyDocument:
            Statement:
              - Sid: Stmt1403287045000
                Effect: Allow
                Action:
                  - 'ec2:AssociateIamInstanceProfile'
                  - 'ec2:AttachVolume'
                  - 'ec2:AuthorizeSecurityGroupEgress'
                  - 'ec2:AuthorizeSecurityGroupIngress'
                  - 'ec2:CancelSpotInstanceRequests'
                  - 'ec2:CreateTags'
                  - 'ec2:CreateVolume'
                  - 'ec2:DeleteTags'
                  - 'ec2:DeleteVolume'
                  - 'ec2:DescribeAvailabilityZones'
                  - 'ec2:DescribeIamInstanceProfileAssociations'
                  - 'ec2:DescribeInstanceStatus'
                  - 'ec2:DescribeInstances'
                  - 'ec2:DescribeInternetGateways'
                  - 'ec2:DescribeNatGateways'
                  - 'ec2:DescribeNetworkAcls'
                  - 'ec2:DescribePrefixLists'
                  - 'ec2:DescribeReservedInstancesOfferings'
                  - 'ec2:DescribeRouteTables'
                  - 'ec2:DescribeSecurityGroups'
                  - 'ec2:DescribeSpotInstanceRequests'
                  - 'ec2:DescribeSpotPriceHistory'
                  - 'ec2:DescribeSubnets'
                  - 'ec2:DescribeVolumes'
                  - 'ec2:DescribeVpcAttribute'
                  - 'ec2:DescribeVpcs'
                  - 'ec2:DetachVolume'
                  - 'ec2:DisassociateIamInstanceProfile'
                  - 'ec2:ReplaceIamInstanceProfileAssociation'
                  - 'ec2:RequestSpotInstances'
                  - 'ec2:RevokeSecurityGroupEgress'
                  - 'ec2:RevokeSecurityGroupIngress'
                  - 'ec2:RunInstances'
                  - 'ec2:TerminateInstances'
                Resource:
                  - '*'
              - Effect: Allow
                Action:
                  - 'iam:CreateServiceLinkedRole'
                  - 'iam:PutRolePolicy'
                Resource:
                  - !Sub arn:${AWS::Partition}:iam::*:role/aws-service-role/spot.amazonaws.com/AWSServiceRoleForEC2Spot
                Condition:
                  StringLike:
                    'iam:AWSServiceName': spot.amazonaws.com
              - Effect: Allow
                Action:
                  - 'iam:PassRole'
                Resource:
                  - !Sub 'arn:aws:iam::${AWS::AccountId}:role/${DatabricksS3SecureAccessRoleName}'
            Version: 2012-10-17
          PolicyName: databricks-cross-account-iam-role-policy
      Tags:
        -
          Key: Name
          Value: !Sub '${TagValue}-IAMRole'

# THE FOLLOWING RESOURCES CONFIGURE THE S3 ROOT BUCKET AND THE ASSOCIATED POLICY.
#
# S3 root bucket requirements
  assetsS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref BucketName
      PublicAccessBlockConfiguration:
        BlockPublicAcls       : true
        BlockPublicPolicy     : true
        IgnorePublicAcls      : true
        RestrictPublicBuckets : true
      VersioningConfiguration:
        Status: Enabled
      InventoryConfigurations:
          - Destination:
              BucketArn: !Join ['', ['arn:aws:s3:::', 'local-logs-bucket', '-', !Ref 'AWS::AccountId', '-', !Ref 'AWS::Region' ]]
              Format: 'CSV'
              Prefix: !Sub 'AWSLogs/${AWS::AccountId}/S3Logs/${AWS::AccountId}-${AWS::Region}-${BucketName}/inventory'
            Enabled: 'true'
            Id: Inventory
            IncludedObjectVersions: 'Current'
            OptionalFields:
              - "Size"
              - "LastModifiedDate"
              - "StorageClass"
              - "ETag"
              - "EncryptionStatus"
            ScheduleFrequency: Weekly

      LifecycleConfiguration:
        Rules:
          -
            Id: "ObjectsLifeCycle"
            NoncurrentVersionTransitions:
                - StorageClass: !Ref FirstTransitionStorageClass
                  TransitionInDays: !Ref FirstTransitionInDays
                - StorageClass: !Ref SecondTransitionStorageClass
                  TransitionInDays: !Ref SecondTransitionInDays
                - StorageClass: !Ref ThirdTransitionStorageClass
                  TransitionInDays: !Ref ThirdTransitionInDays

            Transitions:
              - StorageClass: !Ref FirstTransitionStorageClass
                TransitionInDays: !Ref FirstTransitionInDays
              - StorageClass: !Ref SecondTransitionStorageClass
                TransitionInDays: !Ref SecondTransitionInDays
              - StorageClass: !Ref ThirdTransitionStorageClass
                TransitionInDays: !Ref ThirdTransitionInDays

            ExpirationInDays: !Ref ExpirationInDays
            Status: Enabled

      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
                SSEAlgorithm: aws:kms
                KMSMasterKeyID: !GetAtt CustomerManagedKey.Arn

      LoggingConfiguration:
        DestinationBucketName: !Sub local-logs-bucket-${AWS::AccountId}-${AWS::Region}
        LogFilePrefix: !Sub 'AWSLogs/${AWS::AccountId}/S3Logs/${AWS::AccountId}-${AWS::Region}-${BucketName}/'


      Tags:
        -
          Key: BucketType
          Value: 'Permanent'
        -
          Key: bucketname
          Value: !Ref 'BucketName'
        -
          Key: bucketencryption
          Value: 'aws:kms'
        -
          Key: DataClassification
          Value: !Ref 'DataClassification'
        -
          Key: app
          Value: !Ref app
        -
          Key: uai
          Value: !Ref uai
        -
          Key: role
          Value: !Ref role
        -
          Key: env
          Value: !Ref env

  applicationDataS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref ApplicationDataS3BucketName
      PublicAccessBlockConfiguration:
        BlockPublicAcls       : true
        BlockPublicPolicy     : true
        IgnorePublicAcls      : true
        RestrictPublicBuckets : true
      VersioningConfiguration:
        Status: Enabled
      InventoryConfigurations:
          - Destination:
              BucketArn: !Join ['', ['arn:aws:s3:::', 'local-logs-bucket', '-', !Ref 'AWS::AccountId', '-', !Ref 'AWS::Region' ]]
              Format: 'CSV'
              Prefix: !Sub 'AWSLogs/${AWS::AccountId}/S3Logs/${AWS::AccountId}-${AWS::Region}-${ApplicationDataS3BucketName}/inventory'
            Enabled: 'true'
            Id: Inventory
            IncludedObjectVersions: 'Current'
            OptionalFields:
              - "Size"
              - "LastModifiedDate"
              - "StorageClass"
              - "ETag"
              - "EncryptionStatus"
            ScheduleFrequency: Weekly

      LifecycleConfiguration:
        Rules:
          -
            Id: "ObjectsLifeCycle"
            NoncurrentVersionTransitions:
                - StorageClass: !Ref FirstTransitionStorageClass
                  TransitionInDays: !Ref FirstTransitionInDays
                - StorageClass: !Ref SecondTransitionStorageClass
                  TransitionInDays: !Ref SecondTransitionInDays
                - StorageClass: !Ref ThirdTransitionStorageClass
                  TransitionInDays: !Ref ThirdTransitionInDays

            Transitions:
              - StorageClass: !Ref FirstTransitionStorageClass
                TransitionInDays: !Ref FirstTransitionInDays
              - StorageClass: !Ref SecondTransitionStorageClass
                TransitionInDays: !Ref SecondTransitionInDays
              - StorageClass: !Ref ThirdTransitionStorageClass
                TransitionInDays: !Ref ThirdTransitionInDays

            ExpirationInDays: !Ref ExpirationInDays
            Status: Enabled

      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
                SSEAlgorithm: aws:kms
                KMSMasterKeyID: !GetAtt CustomerManagedKey.Arn

      LoggingConfiguration:
        DestinationBucketName: !Sub local-logs-bucket-${AWS::AccountId}-${AWS::Region}
        LogFilePrefix: !Sub 'AWSLogs/${AWS::AccountId}/S3Logs/${AWS::AccountId}-${AWS::Region}-${ApplicationDataS3BucketName}/'


      Tags:
        -
          Key: BucketType
          Value: 'Permanent'
        -
          Key: bucketname
          Value: !Ref 'ApplicationDataS3BucketName'
        -
          Key: bucketencryption
          Value: 'aws:kms'
        -
          Key: DataClassification
          Value: !Ref 'DataClassification'
        -
          Key: app
          Value: !Ref app
        -
          Key: uai
          Value: !Ref uai
        -
          Key: role
          Value: !Ref role
        -
          Key: env
          Value: !Ref env

  HvrStagingS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref HVRStagingS3BucketName
      PublicAccessBlockConfiguration:
        BlockPublicAcls       : true
        BlockPublicPolicy     : true
        IgnorePublicAcls      : true
        RestrictPublicBuckets : true
      VersioningConfiguration:
        Status: Enabled
      InventoryConfigurations:
          - Destination:
              BucketArn: !Join ['', ['arn:aws:s3:::', 'local-logs-bucket', '-', !Ref 'AWS::AccountId', '-', !Ref 'AWS::Region' ]]
              Format: 'CSV'
              Prefix: !Sub 'AWSLogs/${AWS::AccountId}/S3Logs/${AWS::AccountId}-${AWS::Region}-${HVRStagingS3BucketName}/inventory'
            Enabled: 'true'
            Id: Inventory
            IncludedObjectVersions: 'Current'
            OptionalFields:
              - "Size"
              - "LastModifiedDate"
              - "StorageClass"
              - "ETag"
              - "EncryptionStatus"
            ScheduleFrequency: Weekly

      LifecycleConfiguration:
        Rules:
          -
            Id: "ObjectsLifeCycle"
            NoncurrentVersionTransitions:
                - StorageClass: !Ref FirstTransitionStorageClass
                  TransitionInDays: !Ref FirstTransitionInDays
                - StorageClass: !Ref SecondTransitionStorageClass
                  TransitionInDays: !Ref SecondTransitionInDays
                - StorageClass: !Ref ThirdTransitionStorageClass
                  TransitionInDays: !Ref ThirdTransitionInDays

            Transitions:
              - StorageClass: !Ref FirstTransitionStorageClass
                TransitionInDays: !Ref FirstTransitionInDays
              - StorageClass: !Ref SecondTransitionStorageClass
                TransitionInDays: !Ref SecondTransitionInDays
              - StorageClass: !Ref ThirdTransitionStorageClass
                TransitionInDays: !Ref ThirdTransitionInDays

            ExpirationInDays: !Ref ExpirationInDays
            Status: Enabled

      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
                SSEAlgorithm: aws:kms
                KMSMasterKeyID: !GetAtt CustomerManagedKey.Arn

      LoggingConfiguration:
        DestinationBucketName: !Sub local-logs-bucket-${AWS::AccountId}-${AWS::Region}
        LogFilePrefix: !Sub 'AWSLogs/${AWS::AccountId}/S3Logs/${AWS::AccountId}-${AWS::Region}-${HVRStagingS3BucketName}/'


      Tags:
        -
          Key: BucketType
          Value: 'Permanent'
        -
          Key: bucketname
          Value: !Ref 'HVRStagingS3BucketName'
        -
          Key: bucketencryption
          Value: 'aws:kms'
        -
          Key: DataClassification
          Value: !Ref 'DataClassification'
        -
          Key: app
          Value: !Ref app
        -
          Key: uai
          Value: !Ref uai
        -
          Key: role
          Value: !Ref role
        -
          Key: env
          Value: !Ref env

#Databricks and S3 Secure access role.
  S3SecureAccessRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Ref DatabricksS3SecureAccessRoleName
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: databricks-s3-secure-access-policy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 's3:ListBucket'
                  - 's3:PutObject'
                  - 's3:GetObject'
                  - 's3:DeleteObject'
                  - 's3:PutObjectAcl'
                Resource:
                  - !Sub 'arn:${AWS::Partition}:s3:::${applicationDataS3Bucket}/*'
                  - !Sub 'arn:${AWS::Partition}:s3:::${applicationDataS3Bucket}'
                  - !Sub 'arn:${AWS::Partition}:s3:::${HvrStagingS3Bucket}/*'
                  - !Sub 'arn:${AWS::Partition}:s3:::${HvrStagingS3Bucket}'
                  - !Sub 'arn:${AWS::Partition}:s3:::${DataMigration3BucketName}/*'
                  - !Sub 'arn:${AWS::Partition}:s3:::${DataMigration3BucketName}'
                  - !Sub 'arn:${AWS::Partition}:s3:::${Sftp3BucketName}/*'
                  - !Sub 'arn:${AWS::Partition}:s3:::${Sftp3BucketName}'
        - PolicyName: glue
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - "glue:BatchCreatePartition"
                  - "glue:BatchDeletePartition"
                  - "glue:BatchGetPartition"
                  - "glue:CreateDatabase"
                  - "glue:CreateTable"
                  - "glue:CreateUserDefinedFunction"
                  - "glue:DeleteDatabase"
                  - "glue:DeletePartition"
                  - "glue:DeleteTable"
                  - "glue:DeleteUserDefinedFunction"
                  - "glue:GetDatabase"
                  - "glue:GetDatabases"
                  - "glue:GetPartition"
                  - "glue:GetPartitions"
                  - "glue:GetTable"
                  - "glue:GetTables"
                  - "glue:GetUserDefinedFunction"
                  - "glue:GetUserDefinedFunctions"
                  - "glue:UpdateDatabase"
                  - "glue:UpdatePartition"
                  - "glue:UpdateTable"
                  - "glue:UpdateUserDefinedFunction"
                Resource: '*'

  # Creating Instance profile role and attached the above role
  IAMInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    DependsOn: S3SecureAccessRole
    Properties:
      InstanceProfileName: !Ref DatabricksIAMInstanceProfileName
      Roles:
        - !Ref DatabricksS3SecureAccessRoleName

  # Application Data S3 bucket policy
  applicationbucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties: 
      PolicyDocument:
        Id: MyPolicy1
        Version: 2012-10-17
        Statement:
          - Sid: Grant Databricks Access
            Effect: Allow
            Principal:
              AWS: [arn:aws:iam::414351767826:root,!Sub 'arn:aws:iam::${AWS::AccountId}:role/${DatabricksS3SecureAccessRoleName}']
            Action:
              - 's3:GetObject'
              - 's3:GetObjectVersion'
              - 's3:PutObject'
              - 's3:DeleteObject'
              - 's3:ListBucket'
              - 's3:GetBucketLocation'
            Resource:
              - !Sub 'arn:${AWS::Partition}:s3:::${applicationDataS3Bucket}/*'
              - !Sub 'arn:${AWS::Partition}:s3:::${applicationDataS3Bucket}'
      Bucket: !Ref applicationDataS3Bucket

  # HVR Staging Data S3 bucket policy
  hvrbucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      PolicyDocument:
        Id: MyPolicy2
        Version: 2012-10-17
        Statement:
          - Sid: Grant Databricks Access
            Effect: Allow
            Principal:
              AWS: [arn:aws:iam::414351767826:root,!Sub 'arn:aws:iam::${AWS::AccountId}:role/${DatabricksS3SecureAccessRoleName}','arn:aws:iam::492944730949:role/hvrroleRole']
            Action:
              - "s3:GetObject"
              - "s3:Get*"
              - "s3:List*"
              - "s3:PutBucketCORS"
              - "s3:PutBucketLogging"
              - "s3:PutBucketNotification"
              - "s3:PutBucketObjectLockConfiguration"
              - "s3:PutBucketOwnershipControls"
              - "s3:PutBucketRequestPayment"
              - "s3:PutBucketVersioning"
              - "s3:PutBucketWebsite"
              - "s3:PutEncryptionConfiguration"
              - "s3:PutInventoryConfiguration"
              - "s3:PutLifecycleConfiguration"
              - "s3:PutMetricsConfiguration"
              - "s3:PutReplicationConfiguration"
              - "s3:AbortMultipartUpload"
              - "s3:DeleteObject"
              - "s3:DeleteObjectVersion"
              - "s3:PutObject"
              - "s3:PutObjectLegalHold"
              - "s3:PutObjectRetention"
              - "s3:ReplicateDelete"
              - "s3:ReplicateObject"
              - "s3:RestoreObject"
              - "s3:DeleteObjectTagging"
              - "s3:DeleteObjectVersionTagging"
              - "s3:PutObjectTagging"
              - "s3:PutObjectVersionTagging"
              - "s3:ReplicateTags"
              - "s3:PutBucketTagging"
            Resource:
              - !Sub 'arn:${AWS::Partition}:s3:::${HvrStagingS3Bucket}/*'
              - !Sub 'arn:${AWS::Partition}:s3:::${HvrStagingS3Bucket}'
      Bucket: !Ref HvrStagingS3Bucket

  VPCLookupUtil:
    Type: Custom::VPCLookup
    Properties:
      ServiceToken: !Join
        - ':'
        - - 'arn:aws:lambda'
          - !Ref AWS::Region
          - !Ref AWS::AccountId
          - 'BHCHelperLambdaUtilities'
      method: vpc_lookup
  GetVPCEndpointId:
    Type: Custom::sat-provision-sc-product
    Properties:
      ServiceToken: !Join
        - ':'
        - - 'arn:aws:lambda'
          - !Ref AWS::Region
          - !Ref AWS::AccountId
          - 'BHCHelper-provision-vpc-endpoint-sc'
      VpcEndpointType: Gateway
      ServiceName: s3

 # S3 root bucket policy
  bucketPolicy:
    Type: 'AWS::S3::BucketPolicy'
    Properties:
      PolicyDocument:
        Id: MyPolicy
        Version: 2012-10-17
        Statement:
          - Sid: Grant Databricks Access
            Effect: Allow
            Principal:
              AWS: arn:aws:iam::414351767826:root
            Action:
              - 's3:GetObject'
              - 's3:GetObjectVersion'
              - 's3:PutObject'
              - 's3:DeleteObject'
              - 's3:ListBucket'
              - 's3:GetBucketLocation'
            Resource:
              - !Sub 'arn:${AWS::Partition}:s3:::${assetsS3Bucket}/*'
              - !Sub 'arn:${AWS::Partition}:s3:::${assetsS3Bucket}'
#          -
#              Sid: 'S3xSecureTransport'
#              Effect: Deny
#              Principal: "*"
#              Action: "s3:*"
#              Resource:
#                - !Join ['', ['arn:aws:s3:::', !Ref 'AWS::AccountId' , '-', !Ref 'AWS::Region' ,'-', !Ref "BucketName", /* ]]
#                - !Join ['', ['arn:aws:s3:::', !Ref 'AWS::AccountId' , '-', !Ref 'AWS::Region' ,'-', !Ref "BucketName"]]
#              Condition:
#                Bool:
#                  aws:SecureTransport: false
##          -
##              Sid: 'VPCRestriction' # Specific VPC and Specific VPC Endpoint
##              Effect: Deny
##              NotPrincipal:
##                Service:
##                  - 's3.amazonaws.com'
##                  - 'lambda.amazonaws.com'
##                  - 'events.amazonaws.com'
##                  - 'ec2.amazonaws.com'
##                Principal:
##                  AWS: arn:aws:iam::414351767826:root
##              Action: "s3:*"
##              Resource:
##                - !Join ['', ['arn:aws:s3:::', !Ref 'AWS::AccountId' , '-', !Ref 'AWS::Region' ,'-', !Ref "BucketName" , /* ]]
##                - !Join ['', ['arn:aws:s3:::', !Ref 'AWS::AccountId' , '-', !Ref 'AWS::Region' ,'-', !Ref "BucketName"]]
##              Condition:
##                StringNotEquals:
##                  aws:sourceVpce: !GetAtt GetVPCEndpointId.vpce_Id
##                  aws:sourceVpc: !GetAtt VPCLookupUtil.VPCId
##                ArnNotLike:
##                  aws:PrincipalArn:
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "SC-LaunchConstraint" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCAdmin" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCNetworkAdmin" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCAuditor" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCSecurity" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCDBAdmin" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCRead" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCBilling" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCOperations" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCPowerUser" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCDeveloper" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCStandardUser" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCStandardPlus" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "HelixConnectorReaderRole" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "HelixConnectorWriterRole" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "SC-SFTP-*" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "aws-service-role/access-analyzer.amazonaws.com/AWSServiceRoleForAccessAnalyzer" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "aws-service-role/s3.data-source.lustre.fsx.amazonaws.com/AWSServiceRoleForFSxS3Access_*" ]]
##                     - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', 'SC-csrc-exception-role-', !Ref "AWS::Region" ]]
##          -
##            Sid: 'DenyAccess'
##            NotPrincipal:
##              Service:
##                  - 's3.amazonaws.com'
##                  - 'lambda.amazonaws.com'
##                  - 'events.amazonaws.com'
##                  - 'ec2.amazonaws.com'
##            Action: 's3:*'
##            Effect: Deny
##            Condition:
##               ArnNotLike:
##                aws:PrincipalArn:
##                  !Split
##                    - ","
##                    - !Join
##                      - ","
##                      - - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCAdmin" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCNetworkAdmin" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCAuditor" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCSecurity" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCDBAdmin" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCRead" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCBilling" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCOperations" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCPowerUser" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCDeveloper" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCStandardUser" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "FSCStandardPlus" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "SC-LaunchConstraint" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "HelixConnectorReaderRole" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "HelixConnectorWriterRole" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "SC-SFTP-*" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "aws-service-role/access-analyzer.amazonaws.com/AWSServiceRoleForAccessAnalyzer" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', "aws-service-role/s3.data-source.lustre.fsx.amazonaws.com/AWSServiceRoleForFSxS3Access_*" ]]
##                        - !Join [ "" , ['arn:aws:iam::', !Ref "AWS::AccountId", ':role/', 'SC-csrc-exception-role-', !Ref "AWS::Region" ]]
##            Resource:
##              - !Join ['', ['arn:aws:s3:::', !Ref 'AWS::AccountId' , '-', !Ref 'AWS::Region' ,'-', !Ref "BucketName" , /* ]]
##              - !Join ['', ['arn:aws:s3:::', !Ref 'AWS::AccountId' , '-', !Ref 'AWS::Region' ,'-', !Ref "BucketName" ]]
#          -
#            Sid: DenyS3PresignedUrl
#            Effect: Deny
#            Principal: "*"
#            Action:
#              - s3:*
#            Resource:
#              - !Join ['', ['arn:aws:s3:::', !Ref 'AWS::AccountId' , '-', !Ref 'AWS::Region' ,'-', !Ref "BucketName" , /* ]]
#            Condition:
#              StringNotEquals:
#                s3:x-amz-content-sha256: UNSIGNED-PAYLOAD
#              StringNotLike:
#                s3:authType: REST-HEADER
#              NumericGreaterThan:
#                s3:signatureAge: 600

      Bucket: !Ref assetsS3Bucket

  CustomerManagedKey:
    Type: 'AWS::KMS::Key'
    Properties:
      Description: KMS key used to encrypted Databricks data
      KeyPolicy:
        Version: 2012-10-17
        Id: key-default-1
        Statement:
          - Sid: Enable IAM user permissions
            Effect: Allow
            Principal:
              AWS: !Sub 'arn:aws:iam::${AWS::AccountId}:root'
            Action: 'kms:*'
            Resource: '*'
          - Sid: Enable IAM user permissions to HVR
            Effect: Allow
            Principal:
              AWS: !Sub 'arn:aws:iam::492944730949:role/hvrroleRole'
            Action: 'kms:*'
            Resource: '*'
      Tags:
        - Key: app
          Value: !Ref app
        - Key: uai
          Value: !Ref uai
        - Key: env
          Value: !Ref env
  CustomerManagedKeyAlias:
    Type: 'AWS::KMS::Alias'
    Properties:
      AliasName: !Sub alias/${NewKMSKeyAlias}
      TargetKeyId: !GetAtt CustomerManagedKey.KeyId
#
# THE FOLLOWING RESOURCES INVOKE DATABRICKS APIs
#

# Databricks API for configuring notebook encryption with a customer managed AWS KMS, if provided
#  createCustomerManagedKey:
#    Condition: CMKEncrypted
#    DependsOn: updateCustomManagedKeys
#    Type: Custom::CreateCustomerManagedKey
#    Properties:
#      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
#      action: 'CREATE_CUSTOMER_MANAGED_KEY'
#      accountId: !Ref AccountId
#      key_arn: !GetAtt CustomerManagedKey.Arn
#      key_alias: !Ref CustomerManagedKeyAlias
#      use_cases: !Ref KeyUseCases
#      reuse_key_for_cluster_volumes: !Ref KeyReuseForClusterVolumes
#      encodedbase64:
#        Fn::Base64: !Join
#          - ':'
#          - - !Ref 'Username'
#            - !Ref 'Password'
#      user_agent: 'databricks-CloudFormation-provider'

# Databricks API for workspace credentials
#  createCredentials:
#    Type: Custom::CreateCredentials
#    Properties:
#      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
#      action: 'CREATE_CREDENTIALS'
#      accountId: !Ref AccountId
#      credentials_name: !Join
#        - '-'
#        - - !Ref DeploymentName
#          - 'credentials'
#      role_arn: !If [CreateCrossAccountIAMRole, !GetAtt accessRoleCustomerManagedVPC.Arn, !Ref ExistingCrossAccountIAMRoleARN]
#      encodedbase64:
#        Fn::Base64: !Join
#          - ':'
#          - - !Ref 'Username'
#            - !Ref 'Password'
#      user_agent: 'databricks-CloudFormation-provider'

# Databricks API for workspace storage configuration
#  createStorageConfiguration:
#    Type: Custom::CreateStorageConfigurations
#    Properties:
#      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
#      action: 'CREATE_STORAGE_CONFIGURATIONS'
#      accountId: !Ref AccountId
#      storage_config_name: !Join
#        - '-'
#        - - !Ref 'DeploymentName'
#          - 'storage'
#      s3bucket_name: !Ref assetsS3Bucket
#      encodedbase64:
#        Fn::Base64: !Join
#          - ':'
#          - - !Ref 'Username'
#            - !Ref 'Password'
#      user_agent: 'databricks-CloudFormation-provider'

# Databricks API for customer managed VPC
#  createNetworks:
#    DependsOn: createStorageConfiguration
#    Type: Custom::createNetworks
#    Properties:
#      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
#      action: 'CREATE_NETWORKS'
#      accountId: !Ref AccountId
#      network_name: !Join
#        - '-'
#        - - !Ref 'DeploymentName'
#          - 'network'
#      vpc_id: !If [HasExistingVPC, !Ref VPCID, !Ref customerManagedVPC]
#      subnet_ids: !If [HasExistingVPC, !Ref SubnetIDs, !Join [',', [!Ref privateSubnet1, !Ref privateSubnet2]]]
#      security_group_ids: !If [HasExistingVPC, !Ref SecurityGroupIDs, !Ref SecurityGroup]
#      encodedbase64:
#        Fn::Base64: !Join
#          - ':'
#          - - !Ref 'Username'
#            - !Ref 'Password'
#      user_agent: 'databricks-CloudFormation-provider'

# Databricks API for workspace creation
#  createWorkspace:
#    Type: Custom::CreateWorkspace
#    Properties:
#      ServiceToken: !GetAtt 'databricksApiFunction.Arn'
#      action: 'CREATE_WORKSPACES'
#      accountId: !Ref AccountId
#      workspace_name: !Join
#        - '-'
#        - - !Ref 'DeploymentName'
#          - 'workspace'
#      deployment_name: !Ref 'DeploymentName'
#      aws_region: !Ref AWSRegion
#      credentials_id: !GetAtt createCredentials.CredentialsId
#      storage_config_id: !GetAtt createStorageConfiguration.StorageConfigId
#      encodedbase64:
#        Fn::Base64: !Join
#          - ':'
#          - - !Ref 'Username'
#            - !Ref 'Password'
#      network_id: !GetAtt createNetworks.NetworkId
#      customer_managed_key_id: !If [CMKEncrypted, !GetAtt 'createCustomerManagedKey.CustomerManagedKeyId', '']
#      pricing_tier: !Ref PricingTier
#      hipaa_parm: !Ref HIPAAparm
#      customer_name: ''
#      authoritative_user_email: ''
#      authoritative_user_full_name: ''
#      user_agent: 'databricks-CloudFormation-provider'

  updateIAMSecurityGroupIds:
    DependsOn: updateIAMRoleFunction
    Type: Custom::UpdateRoleAssumePolicy
    Properties:
      ServiceToken: !GetAtt 'updateIAMRoleFunction.Arn'
      # Hard Coded
      role_name: !If [CreateCrossAccountIAMRole, !Ref NewCrossAccountIAMRoleName, !Ref ExistingCrossAccountIAMRoleName]
      aws_region: !Ref AWSRegion
      accountId: !Ref AWS::AccountId
      security_group_ids: !Ref SecurityGroupIDs
      VPCID: !If [HasExistingVPC, !Ref VPCID, !Ref customerManagedVPC]

# Customer managed Keys - Update Storage policy for S3 and EBS volumes
  updateCustomManagedKeys:
    Condition: CMKEncrypted
    DependsOn: updateKMSkeysFunction
    Type: Custom::updateCustomManagedKeys
    Properties:
      ServiceToken: !GetAtt 'updateKMSkeysFunction.Arn'
      key_id: !GetAtt CustomerManagedKey.Arn
      arn_credentials: !If [CreateCrossAccountIAMRole, !GetAtt 'accessRoleCustomerManagedVPC.Arn', !Ref ExistingCrossAccountIAMRoleARN]
      use_cases: !Ref KeyUseCases
      reuse_key_for_cluster_volumes: !Ref KeyReuseForClusterVolumes

# Databricks main Lambda for all E2 objects and workspace creation
  databricksApiFunction:
    DependsOn: CopyZips
    Type: AWS::Lambda::Function
    Properties:
      Description: Databricks account API.
      Handler: rest_client.handler
      Runtime: python3.8
      Role: !GetAtt 'functionRole.Arn'
      Timeout: 900
      Code:
        S3Bucket: !Ref 'LambdaZipsBucket'
        S3Key: !Sub '${QSS3KeyPrefix}functions/packages/lambda.zip'

  updateIAMRoleFunction:
    DependsOn: CopyZips
    Type: AWS::Lambda::Function
    Properties:
      Description: Update IAM role policy document using the list of security group IDs.
      Handler: update_custommanagedvpc_iam_role.handler
      Runtime: python3.8
      Role: !GetAtt 'functionRole.Arn'
      Timeout: 60
      Code:
        S3Bucket: !Ref 'LambdaZipsBucket'
        S3Key: !Sub '${QSS3KeyPrefix}functions/packages/lambda.zip'

  updateKMSkeysFunction:
    Condition: CMKEncrypted
    DependsOn: CopyZips
    Type: AWS::Lambda::Function
    Properties:
      Description: Update CMK policy document for storage.
      Handler: update_custommanaged_cmk_policy.handler
      Runtime: python3.8
      Role: !GetAtt 'functionRole.Arn'
      Timeout: 60
      Code:
        S3Bucket: !Ref 'LambdaZipsBucket'
        S3Key: !Sub '${QSS3KeyPrefix}functions/packages/lambda.zip'

# IAM Role for lambda function execution
  functionRole:
    Type: AWS::IAM::Role
    Metadata:
      cfn-lint:
        config:
          ignore_checks:
            - EIAMPolicyWildcardResource
          ignore_reasons:
            EIAMPolicyWildcardResource: "Need to manage databricks workspaces"
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: kmsUpdateRole
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'kms:GetKeyPolicy'
                  - 'kms:PutKeyPolicy'
                Resource: '*'
        - PolicyName: iamUpdateRole
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'iam:PutRolePolicy'
                Resource: '*'
      Tags:
        -
          Key: Name
          Value: !Sub '${TagValue}-IAMRole'

# Resources to stage lambda.zip file
  LambdaZipsBucket:
    Type: AWS::S3::Bucket
    Properties:
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: 'AES256'
      Tags:
        -
          Key: BucketType
          Value: 'Temporary'
        -
          Key: DataClassification
          Value: !Ref 'DataClassification'
        -
          Key: app
          Value: !Ref app
        -
          Key: uai
          Value: !Ref uai
        -
          Key: role
          Value: !Ref role
        -
          Key: env
          Value: !Ref env
        -
          Key: bucketencryption
          Value: 'AES256'
  CopyZips:
    Type: Custom::CopyZips
    Properties:
      ServiceToken: !GetAtt 'CopyZipsFunction.Arn'
      DestBucket: !Ref 'LambdaZipsBucket'
      SourceBucket: !Ref 'QSS3BucketName'
      Prefix: !Ref 'QSS3KeyPrefix'
      Objects:
        - functions/packages/lambda.zip
  CopyZipsRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - !Sub arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: lambda-copier
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource:
                  - !Sub 'arn:${AWS::Partition}:s3:::${QSS3BucketName}/${QSS3KeyPrefix}*'
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:DeleteObject
                Resource:
                  - !Sub 'arn:${AWS::Partition}:s3:::${LambdaZipsBucket}/${QSS3KeyPrefix}*'
      Tags:
        -
          Key: Name
          Value: !Sub '${TagValue}-IAMRole'


  CopyZipsFunction:
    Type: AWS::Lambda::Function
    Properties:
      Description: Copies objects from an S3 bucket to another destination.
      Handler: index.handler
      Runtime: python3.8
      Role: !GetAtt 'CopyZipsRole.Arn'
      Timeout: 240
      Code:
        ZipFile: |
          import json
          import logging
          import threading
          import boto3
          import cfnresponse
          def copy_objects(source_bucket, dest_bucket, prefix, objects):
              s3 = boto3.client('s3')
              for o in objects:
                  key = prefix + o
                  copy_source = {
                      'Bucket': source_bucket,
                      'Key': key
                  }
                  print('copy_source: %s' % copy_source)
                  print('dest_bucket = %s'%dest_bucket)
                  print('key = %s' %key)
                  s3.copy_object(CopySource=copy_source, Bucket=dest_bucket,
                        Key=key)
          def delete_objects(bucket, prefix, objects):
              s3 = boto3.client('s3')
              objects = {'Objects': [{'Key': prefix + o} for o in objects]}
              s3.delete_objects(Bucket=bucket, Delete=objects)
          def timeout(event, context):
              logging.error('Execution is about to time out, sending failure response to CloudFormation')
              cfnresponse.send(event, context, cfnresponse.FAILED, {}, None)
          def handler(event, context):
              # make sure we send a failure to CloudFormation if the function
              # is going to timeout
              timer = threading.Timer((context.get_remaining_time_in_millis()
                        / 1000.00) - 0.5, timeout, args=[event, context])
              timer.start()
              print('Received event: %s' % json.dumps(event))
              status = cfnresponse.SUCCESS
              try:
                  source_bucket = event['ResourceProperties']['SourceBucket']
                  dest_bucket = event['ResourceProperties']['DestBucket']
                  prefix = event['ResourceProperties']['Prefix']
                  objects = event['ResourceProperties']['Objects']
                  if event['RequestType'] == 'Delete':
                      delete_objects(dest_bucket, prefix, objects)
                  else:
                      copy_objects(source_bucket, dest_bucket, prefix, objects)
              except Exception as e:
                  logging.error('Exception: %s' % e, exc_info=True)
                  status = cfnresponse.FAILED
              finally:
                  timer.cancel()
                  cfnresponse.send(event, context, status, {}, None)
